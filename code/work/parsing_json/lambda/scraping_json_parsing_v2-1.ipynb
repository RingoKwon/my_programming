{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/cs55_cks0_3_zx14p6v7h1_h0000gn/T/ipykernel_17157/3109222412.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_scraping_bill = df_scraping_bill_v2.append(df_scraping_bill_v1)\n",
      "/var/folders/df/cs55_cks0_3_zx14p6v7h1_h0000gn/T/ipykernel_17157/3109222412.py:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_scraping_discount= df_scraping_discount_v2.append(df_scraping_discount_v1)\n"
     ]
    }
   ],
   "source": [
    "import awswrangler  as wr\n",
    "import pandas as pd\n",
    "# import pandas.io.json\n",
    "import pymysql\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "# load sql\n",
    "sql = '''\n",
    "select *\n",
    "from moyo_scraping.mno_scraping_result\n",
    "where 1=1\n",
    "'''\n",
    "sql_v1 = ''' \n",
    "select *\n",
    "from moyo_scraping.mno_scraping_result\n",
    "where 1=1\n",
    "    and version = 1 \n",
    "'''\n",
    "sql_v2 = '''\n",
    "select *\n",
    "from moyo_scraping.mno_scraping_result\n",
    "where 1=1\n",
    "\n",
    "    and version = 2\n",
    "'''\n",
    "df_v1= wr.athena.read_sql_query(sql=sql_v1, database=\"moyo_order\")\n",
    "df_v2= wr.athena.read_sql_query(sql=sql_v2, database=\"moyo_order\")\n",
    "df = wr.athena.read_sql_query(sql=sql, database=\"moyo_order\")\n",
    "\n",
    "request_result = zip(df_v1.request_id, df_v1.result)\n",
    "parsed_data_v1 = []\n",
    "for (request_id, result) in request_result:\n",
    "    parsed_data_v1.append({'request_id': request_id, **json.loads(result)})\n",
    "\n",
    "request_result = zip(df_v2.request_id, df_v2.result)\n",
    "parsed_data_v2 = []\n",
    "for (request_id, result) in request_result:\n",
    "    parsed_data_v2.append({'request_id': request_id, **json.loads(result)})\n",
    "\n",
    "request_result = zip(df.request_id, df.result)\n",
    "parsed_data = []\n",
    "for (request_id, result) in request_result:\n",
    "    parsed_data.append({'request_id': request_id, **json.loads(result)})\n",
    "\n",
    "\n",
    "# load json\n",
    "# main \n",
    "df_scraping_main = pd.json_normalize (parsed_data \n",
    "                , sep = '_'\n",
    "                )\n",
    "\n",
    "bucket = 'moyo-mart'\n",
    "table_name = 'scraping_main'\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df_scraping_main,\n",
    "    path=f\"s3://{bucket}/{table_name}/\",\n",
    "    dataset=True,\n",
    "    database=\"moyo_mart\",\n",
    "    table=table_name,\n",
    "    mode=\"overwrite_partitions\", \n",
    "    # partition_cols=['date_ymd']\n",
    ")\n",
    "#bill- v1, v2\n",
    "df_scraping_bill_v1 = pd.json_normalize (parsed_data_v1 \n",
    "                , sep = '_'\n",
    "                , record_path= ['paymentHistory','billDetails','items'] \n",
    "                , meta = ['request_id',['paymentHistory','billedDate']]\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "df_scraping_bill_v2 = pd.json_normalize (parsed_data_v2\n",
    "                , sep = '_'\n",
    "                , record_path= ['billingHistory','billDetails','items'] \n",
    "                , meta = ['request_id',['paymentHistory','billedDate']]\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "df_scraping_bill = df_scraping_bill_v2.append(df_scraping_bill_v1)\n",
    "bucket = 'moyo-mart'\n",
    "table_name = 'scraping_bill'\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df_scraping_bill,\n",
    "    path=f\"s3://{bucket}/{table_name}/\",\n",
    "    dataset=True,\n",
    "    database=\"moyo_mart\",\n",
    "    table=table_name,\n",
    "    mode=\"overwrite_partitions\", \n",
    "    # partition_cols=['date_ymd']\n",
    ")\n",
    "#discount \n",
    "df_scraping_discount_v1 = pd.json_normalize (parsed_data_v1\n",
    "                , sep = '_'\n",
    "                , record_path= ['paymentHistory','discountDetails','items'] \n",
    "                , meta = ['request_id',['paymentHistory','paidDate']]\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "df_scraping_discount_v2 = pd.json_normalize (parsed_data_v2\n",
    "                , sep = '_'\n",
    "                , record_path= ['billingHistory','discountDetails','items'] \n",
    "                , meta = ['request_id',['billingHistory','billedDate']]\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "df_scraping_discount= df_scraping_discount_v2.append(df_scraping_discount_v1)\n",
    "\n",
    "bucket = 'moyo-mart'\n",
    "table_name = 'scraping_discount'\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df_scraping_discount,\n",
    "    path=f\"s3://{bucket}/{table_name}/\",\n",
    "    dataset=True,\n",
    "    database=\"moyo_mart\",\n",
    "    table=table_name,\n",
    "    mode=\"overwrite_partitions\", \n",
    "    # partition_cols=['date_ymd']\n",
    ")\n",
    "\n",
    "#usage \n",
    "df_scraping_usage = pd.json_normalize (parsed_data \n",
    "                , sep = '_'\n",
    "                , record_path= ['mobileUsageHistory'] \n",
    "                , meta = ['request_id']\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "\n",
    "bucket = 'moyo-mart'\n",
    "table_name = 'scraping_usage'\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df_scraping_usage,\n",
    "    path=f\"s3://{bucket}/{table_name}/\",\n",
    "    dataset=True,\n",
    "    database=\"moyo_mart\",\n",
    "    table=table_name,\n",
    "    mode=\"overwrite_partitions\", \n",
    "    # partition_cols=['date_ymd']\n",
    ")\n",
    "\n",
    "#family\n",
    "df_scraping_family = pd.json_normalize (parsed_data \n",
    "                , sep = '_'\n",
    "                , record_path= ['familyBundleMembers'] \n",
    "                , meta = ['request_id']\n",
    "                # ,meta_prefix=\"main_\"\n",
    "                )\n",
    "\n",
    "bucket = 'moyo-mart'\n",
    "table_name = 'scraping_family'\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df_scraping_family,\n",
    "    path=f\"s3://{bucket}/{table_name}/\",\n",
    "    dataset=True,\n",
    "    database=\"moyo_mart\",\n",
    "    table=table_name,\n",
    "    mode=\"overwrite_partitions\", \n",
    "    # partition_cols=['date_ymd']\n",
    ")\n",
    "\n",
    "\n",
    "# https://s3.console.aws.amazon.com/s3/buckets/moyo-mart?region=ap-northeast-2&prefix=ringo_partition_test/&showversions=false\n",
    "\n",
    "\n",
    "# v1.2 2023.05.23 에 작업함 \n",
    "# billDetails paymentDetails 관련 변경사항 slack 참고 \n",
    "## https://themoyo.slack.com/archives/C04VDRJ29B2/p1684821720087819\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
