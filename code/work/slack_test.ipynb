{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler  as wr\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def send_message_to_slack(text):\n",
    "#     #url = \"https://hooks.slack.com/services/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\"\n",
    "#     url = \"https://hooks.slack.com/services/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\"\n",
    "\n",
    "#     payload = { \n",
    "#                 \"text\" : text,\n",
    "#                 \"icon_emoji\" : ':pepe-phone:',\n",
    "                 \n",
    "#               }\n",
    "\n",
    "\n",
    "#     requests.post(url, json=payload)\n",
    "\n",
    "# def select_triangle(number):\n",
    "#     if number >= 0:\n",
    "#         number = \":up: \" + str(number)\n",
    "#     else:\n",
    "#         number = \":small_red_triangle_down: \" + str(number)\n",
    "#     return number\n",
    "\n",
    "\n",
    "# def lambda_handler(event, context):\n",
    "  \n",
    "#     sql = \"\"\"select date_add('day',-1,date(current_timestamp at time zone 'asia/seoul')) as date_ymd, \n",
    "#                     date_add('month',-1,date_add('day',-1,date(current_timestamp at time zone 'asia/seoul'))) as before_date_ymd\"\"\"\n",
    "  \n",
    "#     date_df = wr.athena.read_sql_query(\n",
    "#         sql=sql,\n",
    "#         database=\"moyo_data\"\n",
    "#     )\n",
    "    \n",
    "#     sql = \"\"\"\n",
    "#     select *,\n",
    "#           lag(servey_count,1) over (order by date_ymd) as lag_servey_count,\n",
    "#           lag(difficulty_score,1) over (order by date_ymd) as lag_difficulty_score,\n",
    "#           lag(problem_solving_time_score,1) over (order by date_ymd) as lag_problem_solving_time_score,\n",
    "#           lag(guidance_score,1) over (order by date_ymd) as lag_guidance_score,\n",
    "#           lag(satisfaction_score,1) over (order by date_ymd) as lag_satisfaction_score,\n",
    "#           lag(friendly_score,1) over (order by date_ymd) as lag_friendly_score\n",
    "#     from\n",
    "#     (SELECT date(reg_ts) as date_ymd, \n",
    "#            count(distinct id) as servey_count,\n",
    "#            round(cast(sum(difficulty_score) as double) / count(distinct id),2) as difficulty_score,\n",
    "#            round(cast(sum(problem_solving_time_score) as double) / count(distinct id),2) as problem_solving_time_score,\n",
    "#            round(cast(sum(guidance_score) as double) / count(distinct id),2) as guidance_score,\n",
    "#            round(cast(sum(satisfaction_score) as double) / count(distinct id),2) as satisfaction_score,\n",
    "#            round(cast(sum(friendly_score) as double) / count(distinct id),2) as friendly_score\n",
    "#     FROM \"moyo_data\".\"cs_survey\"\n",
    "#     where date(reg_ts) <> date(current_timestamp at time zone 'asia/seoul')\n",
    "#     group by 1)\n",
    "#     order by 1 desc\n",
    "#     limit 1\n",
    "#     \"\"\"\n",
    "    \n",
    "#     cs_daily = wr.athena.read_sql_query(\n",
    "#         sql=sql,\n",
    "#         database=\"moyo_data\"\n",
    "#     )\n",
    "\n",
    "#     sql = \"\"\"\n",
    "#     select *,\n",
    "#           coalesce(lag(servey_count,1) over (order by date_ymd),0) as lag_servey_count,\n",
    "#           coalesce(lag(difficulty_score,1) over (order by date_ymd),0) as lag_difficulty_score,\n",
    "#           coalesce(lag(problem_solving_time_score,1) over (order by date_ymd),0) as lag_problem_solving_time_score,\n",
    "#           coalesce(lag(guidance_score,1) over (order by date_ymd),0) as lag_guidance_score,\n",
    "#           coalesce(lag(satisfaction_score,1) over (order by date_ymd),0) as lag_satisfaction_score,\n",
    "#           coalesce(lag(friendly_score,1) over (order by date_ymd),0) as lag_friendly_score\n",
    "#     from\n",
    "#     (SELECT date_format(date(reg_ts),'%Y-%v') as date_ymd,\n",
    "#            min(date(reg_ts)) as min_date_ymd,\n",
    "#            max(date(reg_ts)) as max_date_ymd,\n",
    "#            count(distinct id) as servey_count,\n",
    "#            round(cast(sum(difficulty_score) as double) / count(distinct id),2) as difficulty_score,\n",
    "#            round(cast(sum(problem_solving_time_score) as double) / count(distinct id),2) as problem_solving_time_score,\n",
    "#            round(cast(sum(guidance_score) as double) / count(distinct id),2) as guidance_score,\n",
    "#            round(cast(sum(satisfaction_score) as double) / count(distinct id),2) as satisfaction_score,\n",
    "#            round(cast(sum(friendly_score) as double) / count(distinct id),2) as friendly_score\n",
    "#     FROM \"moyo_data\".\"cs_survey\"\n",
    "#     where date(reg_ts) <> date(current_timestamp at time zone 'asia/seoul')\n",
    "#     group by 1)\n",
    "#     order by 1 desc\n",
    "#     limit 1\n",
    "#     \"\"\"\n",
    "    \n",
    "#     cs_weekly = wr.athena.read_sql_query(\n",
    "#         sql=sql,\n",
    "#         database=\"moyo_data\"\n",
    "#     )\n",
    "\n",
    "\n",
    "#     sql = \"\"\"\n",
    "#     select *,\n",
    "#           coalesce(lag(servey_count,1) over (order by date_ymd),0) as lag_servey_count,\n",
    "#           coalesce(lag(difficulty_score,1) over (order by date_ymd),0) as lag_difficulty_score,\n",
    "#           coalesce(lag(problem_solving_time_score,1) over (order by date_ymd),0) as lag_problem_solving_time_score,\n",
    "#           coalesce(lag(guidance_score,1) over (order by date_ymd),0) as lag_guidance_score,\n",
    "#           coalesce(lag(satisfaction_score,1) over (order by date_ymd),0) as lag_satisfaction_score,\n",
    "#           coalesce(lag(friendly_score,1) over (order by date_ymd),0) as lag_friendly_score\n",
    "#     from\n",
    "#     (SELECT date_format(date(reg_ts),'%Y-%m') as date_ymd, \n",
    "#            count(distinct id) as servey_count,\n",
    "#            round(cast(sum(difficulty_score) as double) / count(distinct id),2) as difficulty_score,\n",
    "#            round(cast(sum(problem_solving_time_score) as double) / count(distinct id),2) as problem_solving_time_score,\n",
    "#            round(cast(sum(guidance_score) as double) / count(distinct id),2) as guidance_score,\n",
    "#            round(cast(sum(satisfaction_score) as double) / count(distinct id),2) as satisfaction_score,\n",
    "#            round(cast(sum(friendly_score) as double) / count(distinct id),2) as friendly_score\n",
    "#     FROM \"moyo_data\".\"cs_survey\"\n",
    "#     where date(reg_ts) <> date(current_timestamp at time zone 'asia/seoul')\n",
    "#     group by 1)\n",
    "#     order by 1 desc\n",
    "#     limit 1\n",
    "#     \"\"\"\n",
    "    \n",
    "#     cs_monthly = wr.athena.read_sql_query(\n",
    "#         sql=sql,\n",
    "#         database=\"moyo_data\"\n",
    "#     )\n",
    "\n",
    "#     text = f\"\"\"\n",
    "#     *일별 cs 통계(기준날짜 : {date_df[\"date_ymd\"][0]})*\n",
    "    \n",
    "#     - cs 수: `{cs_daily[\"servey_count\"][0]}`\n",
    "    \n",
    "#     각 평균 항목별 평균 점수\n",
    "#         - 모요 고객센터 접근과 상담원 연결까지의 과정이 쉬웠나요?: `{cs_daily[\"difficulty_score\"][0]}`\n",
    "#         - 모요로 문의한 문제가 해결 되기까지 소요된 시간은 적절하였나요?: `{cs_daily[\"problem_solving_time_score\"][0]}`\n",
    "#         - 모요 고객센터의 안내로 문제가 해결되었나요?: `{cs_daily[\"guidance_score\"][0]}`\n",
    "#         - 문의에 대한 모요의 업무 처리 방식에 만족하셨나요?: `{cs_daily[\"satisfaction_score\"][0]}`\n",
    "#         - 모요 고객센터는 고객님의 상황에 경청하고 공감하였나요?: `{cs_daily[\"friendly_score\"][0]}`\n",
    "    \n",
    "    \n",
    "#     *주별 cs 통계(기준날짜 : {cs_weekly['min_date_ymd'][0]} ~ {cs_weekly['max_date_ymd'][0]})*\n",
    "\n",
    "#     - cs 수: `{cs_weekly[\"servey_count\"][0]}`\n",
    "    \n",
    "#     각 평균 항목별 평균 점수\n",
    "#         - 모요 고객센터 접근과 상담원 연결까지의 과정이 쉬웠나요?: `{cs_weekly[\"difficulty_score\"][0]}`\n",
    "#         - 모요로 문의한 문제가 해결 되기까지 소요된 시간은 적절하였나요?: `{cs_weekly[\"problem_solving_time_score\"][0]}`\n",
    "#         - 모요 고객센터의 안내로 문제가 해결되었나요?: `{cs_weekly[\"guidance_score\"][0]}`\n",
    "#         - 문의에 대한 모요의 업무 처리 방식에 만족하셨나요?: `{cs_weekly[\"satisfaction_score\"][0]}`\n",
    "#         - 모요 고객센터는 고객님의 상황에 경청하고 공감하였나요?: `{cs_weekly[\"friendly_score\"][0]}`\n",
    "\n",
    "    \n",
    "#     *월별 cs 통계(기준날짜 : {cs_monthly[\"date_ymd\"][0]})*\n",
    "    \n",
    "#     - cs 수: `{cs_monthly[\"servey_count\"][0]}`\n",
    "    \n",
    "#     각 평균 항목별 평균 점수\n",
    "#         - 모요 고객센터 접근과 상담원 연결까지의 과정이 쉬웠나요?: `{cs_monthly[\"difficulty_score\"][0]}`\n",
    "#         - 모요로 문의한 문제가 해결 되기까지 소요된 시간은 적절하였나요?: `{cs_monthly[\"problem_solving_time_score\"][0]}`\n",
    "#         - 모요 고객센터의 안내로 문제가 해결되었나요?: `{cs_monthly[\"guidance_score\"][0]}`\n",
    "#         - 문의에 대한 모요의 업무 처리 방식에 만족하셨나요?: `{cs_monthly[\"satisfaction_score\"][0]}`\n",
    "#         - 모요 고객센터는 고객님의 상황에 경청하고 공감하였나요?: `{cs_monthly[\"friendly_score\"][0]}`\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     send_message_to_slack(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler  as wr\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "sql_query = \"\"\"\n",
    "with ubl_raw as  (\n",
    "/*\n",
    "user_id 병합 쿼리 작업\n",
    "referal 쿼리 작업 cohort\n",
    "*/\n",
    "select\n",
    "  from_iso8601_timestamp(json_extract_scalar(user_properties, '$.first_at'))  + interval '9' hour AS first_at\n",
    ", client_access_time as reg_ts\n",
    ", cast( json_extract_scalar ( event_properties , '$.stay_time_seconds') as integer) as stay_time\n",
    ", case\n",
    "    when device like 'Web%' then case when device like '%Mobile%'  then 'mobile_web'\n",
    "                                when device like '%Desktop%' then  'desktop'  end\n",
    "    when device like 'App%' then 'App'\n",
    "\n",
    "end as device_type\n",
    "-- , row_number ( ) over ( partition by uuid order by client_access_time ) rn\n",
    ", case when\n",
    "    navigation  in (\n",
    "    'home'\n",
    "        ,'unlimited_call_and_data_plans_ranking'\n",
    "        ,'unlimited_data_plans_ranking'\n",
    "        ,'carrier_detail'\n",
    "    ,'search_phones'\n",
    "        , 'phone_detail'\n",
    "        , 'phone_contents'\n",
    "            ,'contents_detail'\n",
    "    ,'faq'\n",
    "    ,    'faq_detail'\n",
    "    ,'search_plans'\n",
    "        ,'plan_detail'\n",
    "        ,'affiliated_curation_page'\n",
    "    ,'events'\n",
    "        ,'event_detail'\n",
    "    ,'search_internets'\n",
    "    ,'qna_home'\n",
    "        ,'qna_post_detail'\n",
    "    ,'my_page'\n",
    "        ,'guide'\n",
    "            ,'guide_detail'\n",
    "        ,'notice'\n",
    "        ,'wishlist'\n",
    "        ,'applied_plans'\n",
    "        ,'recently_plans'\n",
    "        ,'alarm_setting'\n",
    "        ,'creditcard_list'\n",
    "        ,   'card_detail'\n",
    "        ,'oversea_usimsa'\n",
    "        ,'internet_speed_test_start'\n",
    "        ,'account_management'\n",
    "    )\n",
    "    or navigation like 'plan_finder_%'\n",
    "    or  navigation like 'phone_calculator_%'\n",
    "then 1 else 0 end is_coremoyo\n",
    ", json_extract_scalar(user_properties, '$.exp_all_no_huddle_empty_absolute_control_group') absolute_control\n",
    ", row_number() over (partition by uuid order by client_access_time  ) rn\n",
    ", json_extract_scalar(user_properties, '$.initial_utm_medium') initial_utm_medium\n",
    ", json_extract_scalar(user_properties, '$.initial_utm_source') initial_utm_source\n",
    ", json_extract_scalar(user_properties, '$.initial_utm_campaign') initial_utm_campaign\n",
    ", *\n",
    "/*\n",
    " , json_extract_scalar(user_properties, '$.')\n",
    "*/\n",
    "from moyo_logs.user_behavior_logs\n",
    "where 1=1\n",
    "    and date_ymd >= '2023-04-06'\n",
    "\n",
    ")\n",
    "-- user cohort\n",
    ", first_navi as (\n",
    "select\n",
    "*\n",
    "from ubl_raw\n",
    "where 1=1\n",
    "    and rn = 1\n",
    ")\n",
    ", user_agg as (\n",
    "select\n",
    " uuid\n",
    " , sum( stay_time ) as stay_time\n",
    " , sum ( case when is_coremoyo = 1 then stay_time  end )  as stay_time_core\n",
    " , sum ( case when category = 'apply' and object_type = 'plan' then 1 end ) as apply_cnt\n",
    " , sum (case when category = 'pageview' and object_type = 'plan_detail' then 1 end ) as pv_cnt\n",
    "from ubl_raw\n",
    "group by 1\n",
    ")\n",
    "---\n",
    ", ubl_trim as (\n",
    "select\n",
    "a.uuid -- device_id\n",
    ", a.user_id -- user_id\n",
    ", a.absolute_control  --23.4.11 배포\n",
    ", a.device_type\n",
    ", a.reg_ts -- 이벤트 생성일\n",
    ", a.first_at as user_first_at  -- uuid 생성일\n",
    ", a.date_ymd  --\n",
    ", a.navigation\n",
    ", a.is_coremoyo -- moyo 내부지면\n",
    ", a.category  --\n",
    ", a.object_type\n",
    ", a.object_section\n",
    ", a.rn -- uuid 별 이벤트 생성 순서\n",
    ", a.stay_time  as stay_time_sec  -- navigation 별 소비시간\n",
    ", a.initial_utm_source -- 최초 utm\n",
    ", a.initial_utm_medium\n",
    ", a.initial_utm_campaign\n",
    ", b.navigation as user_first_navi  -- 첫 랜딩 지면\n",
    "-- , b.external_referer_url as  first_referer\n",
    ", 1.00* c.stay_time /60 as user_stay_time_all_min -- uuid 가 소비한 total 시간\n",
    ", 1.00* c.stay_time_core /60 as user_stay_time_core_min -- uuid가 moyo 내부지면에서 소비한 total 시간\n",
    ", c.apply_cnt  as user_apply_cnt -- uuid의 요금제 가입 수\n",
    ", c.pv_cnt as user_pv_cnt\n",
    ", 1.00* date_diff ( 'second' , a.first_at , a.reg_ts )/60  as first_to_event_min -- uuid 생성일과 이벤트 생성일간의 차이\n",
    ", a.object_id\n",
    ", a.object_name\n",
    "from ubl_raw a\n",
    "join first_navi b on a.uuid = b.uuid\n",
    "join user_agg c on a.uuid = c.uuid\n",
    "where 1=1\n",
    "-- and first_at is not null\n",
    "and (date( a.date_ymd) >= date( '2023-04-06')\n",
    "        -- and date( date_ymd)\n",
    "            -- < date(current_timestamp AT TIME ZONE 'UTC' AT TIME ZONE 'Asia/Seoul')\n",
    "            -- < date( '2023-04-06')\n",
    "    )\n",
    ")\n",
    "\n",
    "/*  자주 사용하는 이벤트\n",
    " and category = 'apply' and object_type = 'plan'\n",
    " and navigation  = 'rocket_apply_complete' and category = 'server'\n",
    " and and category = 'apply' and object_type = 'plan'\n",
    "*/\n",
    ", raw_prep as (\n",
    "select\n",
    "case when user_first_at is not null then 1 else 0 end first_at_not_null\n",
    ", *\n",
    "from ubl_trim\n",
    "where 1=1\n",
    "    and user_first_at is not null\n",
    ")\n",
    ", final as (\n",
    "select\n",
    " absolute_control\n",
    ", is_coremoyo\n",
    ", case when user_first_navi in ( 'guide_detail', 'contents_detail')\n",
    "            or initial_utm_campaign like 'test%'\n",
    "    or( category= 'pageview' and navigation = 'affiliate_landing' and  object_id like '%paybooc%' and object_id like '%landing%'  and date(reg_ts ) >= date( '2023-04-20') )\n",
    "    then 1 else 0 end as is_target\n",
    " , case when user_fiRst_navi = 'guide_detail' then 'guide_detail'\n",
    "        when user_first_navi = 'contents_detail' then 'contents_detail'\n",
    "        when  initial_utm_campaign like 'test%' then initial_utm_campaign\n",
    "        when ( category= 'pageview' and navigation = 'affiliate_landing' and  object_id like '%paybooc%' and object_id like '%landing%' and date(reg_ts ) >= date( '2023-04-20') )\n",
    "                then 'paybooc'\n",
    "            end as Pop_source\n",
    ", date( user_first_at ) as reg_ts\n",
    ",count(  distinct case when   user_pv_cnt >= 3 or user_apply_cnt >= 1 then uuid end) as cvr_cnt\n",
    ",count(  distinct case when first_to_event_min between 0 and  48*60 /*48시간 */\n",
    "                            and  (user_pv_cnt >= 3 or user_apply_cnt >= 1) then uuid end ) as cvr_cnt_cw48\n",
    ",count(  distinct case when first_to_event_min between 0 and  24*60\n",
    "                            and  (user_pv_cnt >= 3 or user_apply_cnt >= 1) then uuid end ) as cvr_cnt_cw24\n",
    ",count(  distinct case when first_to_event_min between 0 and  72*60\n",
    "                            and  (user_pv_cnt >= 3 or user_apply_cnt >= 1) then uuid end ) as cvr_cnt_cw72\n",
    ",count(  distinct case when first_to_event_min between 0 and  96*60\n",
    "                            and  (user_pv_cnt >= 3 or user_apply_cnt >= 1) then uuid end ) as cvr_cnt_cw96\n",
    "\n",
    ", count( distinct uuid ) as uuid_cnt\n",
    "from raw_prep\n",
    "group by 1,2,3,4,5\n",
    ")\n",
    ", final2 as (\n",
    "select\n",
    "reg_ts\n",
    ", absolute_control\n",
    ", sum (uuid_cnt) as uuid_cnt\n",
    ", sum (cvr_cnt_cw24) as cvr_cnt\n",
    "from final\n",
    "where 1=1\n",
    "    and is_target = 1\n",
    "    and absolute_control is not null\n",
    "group by 1,2\n",
    ")\n",
    ", final3 as (\n",
    "select\n",
    "    *\n",
    ", row_number() over (order by reg_ts desc  ) as rn\n",
    ", DENSE_RANK() over ( order by reg_ts desc ) as dr\n",
    "from final2\n",
    "where 1=1\n",
    ")\n",
    ", final4 as (\n",
    "select\n",
    "    reg_ts\n",
    ", 1.00* cvr_cnt/uuid_cnt as cvr\n",
    ", absolute_control\n",
    "from final3\n",
    "where 1=1\n",
    "    and dr in ( 3,4,5 ,6, 7,8 ,9,10,11,12,13,14)\n",
    ")\n",
    ", final5 as (\n",
    "select\n",
    "reg_ts\n",
    ", max (  case when absolute_control = 'control' then cvr end ) as control\n",
    ", max (  case when absolute_control = 'experimental' then cvr end ) as experimental\n",
    "from final4\n",
    "where 1=1\n",
    "group by 1\n",
    "-- - control\n",
    "-- experimental\n",
    "                )\n",
    "select\n",
    "    *\n",
    ", 1.00*experimental / control - 1 as uplift\n",
    "from final5\n",
    "order by 1 desc\n",
    "\"\"\"\n",
    "\n",
    "df = wr.athena.read_sql_query(sql=sql_query, database=\"moyo_logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>control</th>\n",
       "      <th>experimental</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>1.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>-0.283469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>0.018215</td>\n",
       "      <td>-0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>-0.292771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>1.113741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-02</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>-0.200512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>0.030879</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>-0.309175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.026943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>-0.010137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.279887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>-0.258965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reg_ts   control  experimental    uplift\n",
       "0   2023-05-07  0.012526      0.025225  1.013778\n",
       "1   2023-05-06  0.027149      0.019453 -0.283469\n",
       "2   2023-05-05  0.018832      0.018215 -0.032787\n",
       "3   2023-05-04  0.030476      0.021554 -0.292771\n",
       "4   2023-05-03  0.009560      0.020208  1.113741\n",
       "5   2023-05-02  0.026622      0.021284 -0.200512\n",
       "6   2023-05-01  0.030879      0.021332 -0.309175\n",
       "7   2023-04-30  0.039474      0.040537  0.026943\n",
       "8   2023-04-29  0.033333      0.024094 -0.277191\n",
       "9   2023-04-28  0.028634      0.028344 -0.010137\n",
       "10  2023-04-27  0.023810      0.030474  0.279887\n",
       "11  2023-04-26  0.031496      0.023340 -0.258965"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday's date in short form: 23/05/08\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# Get the current time in UTC\n",
    "now_utc = datetime.now(pytz.utc)\n",
    "\n",
    "# Convert the current time to South Korea's timeone\n",
    "seoul_tz = pytz.timezone('Asia/Seoul')\n",
    "now_seoul = now_utc.astimezone(seoul_tz)\n",
    "\n",
    "# Subtract one day to get yesterday's date\n",
    "yesterday_seoul = now_seoul - timedelta(days=1)\n",
    "\n",
    "# Format the date in a short form\n",
    "short_date = yesterday_seoul.strftime('%y/%m/%d')\n",
    "\n",
    "print(f\"Yesterday's date in short form: {short_date}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# webhook_url = \"https://hooks.slack.com/services/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\" # Replace this with your webhook URL\n",
    "\n",
    "# def send_slack_message(text):\n",
    "#     payload = {\n",
    "# \t\"blocks\": [\n",
    "# \t\t{\n",
    "# \t\t\t\"type\": \"section\",\n",
    "# \t\t\t\"text\": {\n",
    "# \t\t\t\t\"type\": \"mrkdwn\",\n",
    "# \t\t\t\t\"text\": \">*허들이 있는 모두가 알뜰폰 가입을 하고 싶게 만든다*\"\n",
    "# \t\t\t}\n",
    "# \t\t},\n",
    "# \t\t{\n",
    "# \t\t\t\"type\": \"section\",\n",
    "# \t\t\t\"fields\": [\n",
    "# \t\t\t\t{\n",
    "# \t\t\t\t\t\"type\": \"mrkdwn\",\n",
    "# \t\t\t\t\t\"text\": \"*KR* : 134%\"\n",
    "# \t\t\t\t},\n",
    "# \t\t\t\t{\n",
    "# \t\t\t\t\t\"type\": \"mrkdwn\",\n",
    "# \t\t\t\t\t\"text\": \"*달성률* : 4%\"\n",
    "# \t\t\t\t}\n",
    "# \t\t\t]\n",
    "# \t\t},\n",
    "# \t\t{\n",
    "# \t\t\t\"type\": \"actions\",\n",
    "# \t\t\t\"elements\": [\n",
    "# \t\t\t\t{\n",
    "# \t\t\t\t\t\"type\": \"button\",\n",
    "# \t\t\t\t\t\"text\": {\n",
    "# \t\t\t\t\t\t\"type\": \"plain_text\",\n",
    "# \t\t\t\t\t\t\"text\": \"Objective\"\n",
    "# \t\t\t\t\t},\n",
    "# \t\t\t\t\t\"url\": \"https://google.com\",\n",
    "# \t\t\t\t\t\"action_id\": \"Open Objective\"\n",
    "# \t\t\t\t},\n",
    "# \t\t\t\t{\n",
    "# \t\t\t\t\t\"type\": \"button\",\n",
    "# \t\t\t\t\t\"text\": {\n",
    "# \t\t\t\t\t\t\"type\": \"plain_text\",\n",
    "# \t\t\t\t\t\t\"text\": \"KR Dashboard\"\n",
    "# \t\t\t\t\t},\n",
    "# \t\t\t\t\t\"url\": \"https://google.com\",\n",
    "# \t\t\t\t\t\"action_id\": \"Open Dashboard\"\n",
    "# \t\t\t\t}\n",
    "# \t\t\t]\n",
    "# \t\t}\n",
    "# \t]\n",
    "# }\n",
    "#     response = requests.post(webhook_url, data=json.dumps(payload), headers={\"Content-Type\": \"application/json\"})\n",
    "#     return response\n",
    "\n",
    "# # Replace \"Your message here\" with the message you want to send\n",
    "# # send_slack_message(f\"Your message here:\\n{a_column_str}\\n <\"https://www.naver.com/\"|'ss'>\")\n",
    "# send_slack_message(f\"Your message here:\\n{a_column_str}\\n <https://www.naver.com|ss>\")\n",
    "# # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_sdk.errors import SlackApiError\n",
    "\n",
    "# # Replace 'your_bot_token_here' with your actual bot token\n",
    "# slack_bot_token = 'your_bot_token_here'\n",
    "# client = WebClient(token=slack_bot_token)\n",
    "\n",
    "# # Define the QuickChart URL (replace this with your actual chart URL)\n",
    "# chart_url = f\"https://quickchart.io/chart?c={{type:'bar',data:{{labels:['January','February','March'],datasets:[{{label:'Sales',data:[50,75,100]}}]}}}}\"\n",
    "\n",
    "# # Define the target Slack channel\n",
    "# channel = \"https://hooks.slack.com/services/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\" \n",
    "\n",
    "# # Send the Slack message with the chart image\n",
    "# try:\n",
    "#     response = client.chat_postMessage(\n",
    "#         channel=channel,\n",
    "#         blocks=[\n",
    "#             {\n",
    "#                 \"type\": \"image\",\n",
    "#                 \"title\": {\n",
    "#                     \"type\": \"plain_text\",\n",
    "#                     \"text\": \"Sample Chart\"\n",
    "#                 },\n",
    "#                 \"image_url\": chart_url,\n",
    "#                 \"alt_text\": \"A sample bar chart\"\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     print(f\"Message sent to {channel}\")\n",
    "# except SlackApiError as e:\n",
    "#     print(f\"Error sending message: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df.reg_ts = df.reg_ts.apply(str)\n",
    "df.uplift = df.uplift.apply(lambda x: math.floor(x * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df.uplift)\n",
    "a.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(map(str, df.reg_ts.values.tolist()))\n",
    "b.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-04-26',\n",
       " '2023-04-27',\n",
       " '2023-04-28',\n",
       " '2023-04-29',\n",
       " '2023-04-30',\n",
       " '2023-05-01',\n",
       " '2023-05-02',\n",
       " '2023-05-03',\n",
       " '2023-05-04',\n",
       " '2023-05-05',\n",
       " '2023-05-06',\n",
       " '2023-05-07']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_column_str \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mto_string(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "a_column_str = df['a'].to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent\n"
     ]
    }
   ],
   "source": [
    "import json5\n",
    "import requests\n",
    "from urllib import parse\n",
    "\n",
    "# Replace 'your_webhook_url_here' with your actual webhook URL\n",
    "webhook_url = \"https://hooks.slack.com/services/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\" \n",
    "\n",
    "data = {\n",
    "    'type': 'bar',\n",
    "    'data': {\n",
    "        'labels': b,\n",
    "        'datasets': [{\n",
    "            'label': 'KR:완전대조군대비730%달성',\n",
    "            'data': a,\n",
    "            'fill': False,\n",
    "            'borderColor': '#566fee',\n",
    "        }],\n",
    "    },\n",
    "    'options': {\n",
    "        'plugins': {\n",
    "            'datalabels': {\n",
    "                'anchor': 'end',\n",
    "                'align': 'top',\n",
    "                'color': '#425ad5',\n",
    "                'formatter': 'function (value) { return value + \"%\" }',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "data = str(json5.dumps(data))\n",
    "formatter_start = data.find('formatter: ')\n",
    "\n",
    "if formatter_start != -1:\n",
    "    data = data[:formatter_start] + data[formatter_start:].replace('\"', '').replace('\\\\', '\"')\n",
    "\n",
    "encoded_data = parse.urlencode({ 'backgroundColor': '#ffffff', 'c': data })\n",
    "\n",
    "# Define the QuickChart URL (replace this with your actual chart URL)\n",
    "chart_url = f\"https://quickchart.io/chart?{encoded_data}\"\n",
    "\n",
    "# Construct the Slack message payload\n",
    "payload = {\n",
    "    \"blocks\": [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"title\": {\n",
    "                \"type\": \"plain_text\",\n",
    "                \"text\": \"Sample Chart\"\n",
    "            },\n",
    "            \"image_url\": chart_url,\n",
    "            \"alt_text\": \"A sample bar chart\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the Slack message with the chart image using the webhook\n",
    "response = requests.post(\n",
    "    webhook_url,\n",
    "    data=json.dumps(payload),\n",
    "    headers={'Content-Type': 'application/json'}\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Message sent\")\n",
    "else:\n",
    "    print(f\"Error sending message: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "webhook_url = \"https://hooks.slack.com/services/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\" # Replace this with your webhook URL\n",
    "\n",
    "def send_slack_message(text):\n",
    "    payload = {\n",
    "\t\"blocks\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"section\",\n",
    "\t\t\t\"text\": {\n",
    "\t\t\t\t\"type\": \"mrkdwn\",\n",
    "\t\t\t\t\"text\": f'''>*허들이 있는 모두가 알뜰폰 가입을 하고 싶게 만든다*\\n  KR:완전대조군대비730%달성 ({b[-1]}일 기준)'''\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"section\",\n",
    "\t\t\t\"fields\": [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"mrkdwn\",\n",
    "\t\t\t\t\t\"text\": f\"*KR* : {a[-1]}%\" \n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"mrkdwn\",\n",
    "\t\t\t\t\t\"text\": F\"*달성률* : {round(a[-1]/730,2)}%\"\n",
    "\t\t\t\t}\n",
    "\t\t\t]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"actions\",\n",
    "\t\t\t\"elements\": [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"button\",\n",
    "\t\t\t\t\t\"text\": {\n",
    "\t\t\t\t\t\t\"type\": \"plain_text\",\n",
    "\t\t\t\t\t\t\"text\": \"OKR문서\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t\"url\": \"https://www.notion.so/moyoplan/OKR-c1b3a17a86c5465ea7c58da48fb32cfd?pvs=4\",\n",
    "\t\t\t\t\t\"action_id\": \"Open Objective\"\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"button\",\n",
    "\t\t\t\t\t\"text\": {\n",
    "\t\t\t\t\t\t\"type\": \"plain_text\",\n",
    "\t\t\t\t\t\t\"text\": \"KR Dashboard\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t\"url\": \"https://prod-apnortheast-a.online.tableau.com/#/site/moyoplan/views/_OKR_v2/OKR?:iid=1\",\n",
    "\t\t\t\t\t\"action_id\": \"Open Dashboard\"\n",
    "\t\t\t\t}\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "    response = requests.post(webhook_url, data=json.dumps(payload), headers={\"Content-Type\": \"application/json\"})\n",
    "    return response\n",
    "\n",
    "# Replace \"Your message here\" with the message you want to send\n",
    "# send_slack_message(f\"Your message here:\\n{a_column_str}\\n <\"https://www.naver.com/\"|'ss'>\")\n",
    "send_slack_message(f\"Your message here:\\n{a}\\n <https://www.naver.com|ss>\")\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
